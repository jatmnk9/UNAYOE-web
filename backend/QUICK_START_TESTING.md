# ðŸš€ Quick Start - Pruebas UNAYOE Backend

## âš¡ Inicio RÃ¡pido (5 minutos)

### 1. Instalar Dependencias

```bash
cd backend
pip install -r requirements.txt
```

### 2. Configurar Variables de Entorno

Crear archivo `.env` en `backend/`:

```env
SUPABASE_URL="https://test.supabase.co"
SUPABASE_KEY="test_key"
GEMINI_API_KEY="test_key"
```

### 3. Ejecutar Pruebas

```bash
# OpciÃ³n 1: Usar script interactivo (Windows)
run_tests.bat

# OpciÃ³n 2: Usar script interactivo (Linux/Mac)
./run_tests.sh

# OpciÃ³n 3: Comandos directos
pytest -v
```

---

## ðŸ“ Comandos Esenciales

### Ejecutar Todas las Pruebas
```bash
pytest -v
```

### Ejecutar Pruebas por CategorÃ­a

```bash
# Pruebas unitarias
pytest tests/unit -v

# Pruebas de integraciÃ³n
pytest tests/integration -v

# Pruebas de servicios NLP/IA
pytest -m nlp -v
```

### Generar Reporte de Cobertura

```bash
pytest --cov=app --cov-report=html

# Ver reporte (Windows)
start htmlcov/index.html

# Ver reporte (Linux/Mac)
open htmlcov/index.html
```

---

## ðŸŽ¯ Pruebas por MÃ³dulo

### MÃ³dulo 1: Notes + Analysis (NLP/IA)

```bash
# Todas las pruebas del mÃ³dulo
pytest tests/unit/test_nlp_service.py \
       tests/unit/test_analysis_service.py \
       tests/integration/test_notes_analysis_integration.py -v

# Solo servicio NLP
pytest tests/unit/test_nlp_service.py -v

# Solo anÃ¡lisis
pytest tests/unit/test_analysis_service.py -v

# Solo integraciÃ³n
pytest tests/integration/test_notes_analysis_integration.py -v
```

### MÃ³dulo 2: Recommendations

```bash
# Todas las pruebas del mÃ³dulo
pytest tests/integration/test_recommendations_integration.py -v
```

---

## ðŸ” Ejemplos de Pruebas EspecÃ­ficas

### Ejecutar una Prueba Individual

```bash
# Sintaxis: pytest ruta/archivo.py::Clase::test_nombre

# Ejemplo 1: Prueba de sentimiento positivo
pytest tests/unit/test_nlp_service.py::TestNLPService::test_analizar_sentimiento_positivo -v

# Ejemplo 2: Prueba de flujo completo
pytest tests/integration/test_notes_analysis_integration.py::TestNotesAnalysisIntegration::test_flujo_completo_guardar_y_analizar_nota -v
```

### Ejecutar Todas las Pruebas de una Clase

```bash
pytest tests/unit/test_nlp_service.py::TestNLPService -v
```

---

## ðŸ·ï¸ Uso de Marcadores

### Marcadores Disponibles

- `unit` - Pruebas unitarias
- `integration` - Pruebas de integraciÃ³n
- `nlp` - Pruebas de servicios NLP/IA
- `slow` - Pruebas lentas
- `db` - Pruebas que requieren base de datos

### Ejemplos

```bash
# Solo pruebas unitarias
pytest -m unit -v

# Solo pruebas de integraciÃ³n
pytest -m integration -v

# Solo pruebas de NLP/IA
pytest -m nlp -v

# Excluir pruebas lentas
pytest -m "not slow" -v

# Combinaciones
pytest -m "unit and nlp" -v
pytest -m "integration and not slow" -v
```

---

## ðŸ“Š Opciones de Salida

### Salida Detallada

```bash
# Verbose (recomendado)
pytest -v

# Extra verbose
pytest -vv

# Mostrar output de prints
pytest -v -s

# Mostrar solo nombres de pruebas
pytest --collect-only
```

### Salida de Fallos

```bash
# Detalles cortos (por defecto)
pytest --tb=short

# Detalles largos
pytest --tb=long

# Solo una lÃ­nea por fallo
pytest --tb=line

# Sin traceback
pytest --tb=no
```

---

## ðŸŽ¨ Opciones de Cobertura

### Generar Reportes

```bash
# Reporte en terminal
pytest --cov=app --cov-report=term

# Reporte HTML
pytest --cov=app --cov-report=html

# Reporte XML (para CI/CD)
pytest --cov=app --cov-report=xml

# MÃºltiples reportes
pytest --cov=app --cov-report=html --cov-report=term-missing
```

### Ver Archivos sin Cobertura

```bash
pytest --cov=app --cov-report=term-missing
```

### Cobertura de Archivo EspecÃ­fico

```bash
pytest --cov=app/services/nlp_service --cov-report=term
```

---

## ðŸ”§ Opciones Avanzadas

### Ejecutar en Paralelo (MÃ¡s RÃ¡pido)

```bash
# Instalar pytest-xdist
pip install pytest-xdist

# Ejecutar con 4 workers
pytest -n 4

# Ejecutar con auto-detecciÃ³n de CPUs
pytest -n auto
```

### Detener en Primer Fallo

```bash
pytest -x
```

### Detener despuÃ©s de N fallos

```bash
pytest --maxfail=3
```

### Ejecutar Solo Pruebas que Fallaron Anteriormente

```bash
pytest --lf
```

### Ejecutar Primero las que Fallaron

```bash
pytest --ff
```

### Modo Silencioso

```bash
pytest -q
```

---

## ðŸ› Debug de Pruebas

### Ver Variables y Estado

```bash
# Mostrar valores locales en fallos
pytest -v -l

# Modo debug con PDB
pytest --pdb

# PDB solo en fallos
pytest --pdb --maxfail=1
```

### Ver Warnings

```bash
# Mostrar todos los warnings
pytest -v -W all

# Mostrar summary de warnings
pytest -v --warnings=summary
```

---

## ðŸ“¦ Ejemplos de Flujo Completo

### Flujo de Desarrollo Diario

```bash
# 1. Ejecutar pruebas rÃ¡pidas
pytest -m "not slow" -v

# 2. Si todo pasa, ejecutar todas
pytest -v

# 3. Verificar cobertura
pytest --cov=app --cov-report=term-missing

# 4. Ver reporte HTML si es necesario
pytest --cov=app --cov-report=html
start htmlcov/index.html  # Windows
```

### Flujo antes de Commit

```bash
# 1. Ejecutar todas las pruebas
pytest -v

# 2. Generar cobertura
pytest --cov=app --cov-report=term-missing

# 3. Verificar que cobertura > 70%

# 4. Si todo pasa, hacer commit
git add .
git commit -m "feat: nueva funcionalidad con pruebas"
```

### Flujo de CI/CD (simulaciÃ³n local)

```bash
# 1. Pruebas unitarias
pytest tests/unit -v -m unit

# 2. Pruebas NLP/IA
pytest tests/unit -v -m nlp

# 3. Pruebas de integraciÃ³n
pytest tests/integration -v -m integration

# 4. Cobertura completa
pytest --cov=app --cov-report=xml --cov-report=term-missing
```

---

## ðŸŽ“ Tips y Trucos

### 1. Crear Alias en tu Shell

**Bash/Zsh (.bashrc o .zshrc):**
```bash
alias pt="pytest -v"
alias ptc="pytest --cov=app --cov-report=html"
alias ptu="pytest tests/unit -v"
alias pti="pytest tests/integration -v"
alias ptn="pytest -m nlp -v"
```

**PowerShell (perfil):**
```powershell
function pt { pytest -v }
function ptc { pytest --cov=app --cov-report=html }
function ptu { pytest tests/unit -v }
function pti { pytest tests/integration -v }
```

### 2. Usar Watch Mode

```bash
# Instalar pytest-watch
pip install pytest-watch

# Ejecutar en modo watch
ptw
```

### 3. Filtrar por Nombre

```bash
# Buscar pruebas que contengan "sentimiento"
pytest -k "sentimiento" -v

# Buscar pruebas que contengan "nlp" o "analysis"
pytest -k "nlp or analysis" -v

# Buscar pruebas que no contengan "slow"
pytest -k "not slow" -v
```

---

## ðŸ“š Recursos

- **DocumentaciÃ³n Completa:** [README_TESTS.md](README_TESTS.md)
- **Resumen Ejecutivo:** [TESTING_SUMMARY.md](TESTING_SUMMARY.md)
- **ConfiguraciÃ³n:** [pytest.ini](pytest.ini)
- **Fixtures:** [tests/conftest.py](tests/conftest.py)

---

## ðŸ†˜ SoluciÃ³n RÃ¡pida de Problemas

### Error: "ModuleNotFoundError: No module named 'app'"

```bash
# SoluciÃ³n: AsegÃºrate de estar en el directorio backend
cd backend
pytest -v
```

### Error: "No module named 'pytest'"

```bash
# SoluciÃ³n: Instalar dependencias
pip install -r requirements.txt
```

### Pruebas muy lentas

```bash
# SoluciÃ³n: Ejecutar en paralelo
pip install pytest-xdist
pytest -n auto
```

### Ver por quÃ© falla una prueba

```bash
# SoluciÃ³n: Usar modo verbose con locals
pytest -vv -l
```

---

## âœ… Checklist de Primera EjecuciÃ³n

- [ ] Instalar dependencias: `pip install -r requirements.txt`
- [ ] Crear archivo `.env` con variables de prueba
- [ ] Ejecutar todas las pruebas: `pytest -v`
- [ ] Verificar que todas pasen âœ…
- [ ] Generar reporte de cobertura: `pytest --cov=app --cov-report=html`
- [ ] Verificar cobertura > 70%
- [ ] Ver reporte HTML: `start htmlcov/index.html`
- [ ] Leer documentaciÃ³n: [README_TESTS.md](README_TESTS.md)

---

**Â¡Listo para empezar! ðŸš€**

Si tienes dudas, consulta la [documentaciÃ³n completa](README_TESTS.md).
